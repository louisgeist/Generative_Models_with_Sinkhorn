{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!mkdir training_folder && cd training_folder\n",
        "%cd training_folder\n",
        "!git clone https://github.com/louisgeist/Generative_Models_with_Sinkhorn.git\n",
        "%cd Generative_Models_with_Sinkhorn/"
      ],
      "metadata": {
        "id": "AqZTSgbfKrLw",
        "outputId": "7ed48932-11ae-4417-96ea-102f4df9db86",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "AqZTSgbfKrLw",
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/training_folder/training_folder\n",
            "Cloning into 'Generative_Models_with_Sinkhorn'...\n",
            "remote: Enumerating objects: 38, done.\u001b[K\n",
            "remote: Counting objects: 100% (38/38), done.\u001b[K\n",
            "remote: Compressing objects: 100% (29/29), done.\u001b[K\n",
            "remote: Total 38 (delta 15), reused 28 (delta 9), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (38/38), 10.17 KiB | 10.17 MiB/s, done.\n",
            "Resolving deltas: 100% (15/15), done.\n",
            "/content/training_folder/training_folder/Generative_Models_with_Sinkhorn\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "8ea3ad5a",
      "metadata": {
        "id": "8ea3ad5a",
        "outputId": "d3ec153f-b3da-4f44-cf91-8f7ab77b9e71",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ./data/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9912422/9912422 [00:00<00:00, 115579908.61it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/train-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ./data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 28881/28881 [00:00<00:00, 33251631.57it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/train-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1648877/1648877 [00:00<00:00, 24266541.04it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4542/4542 [00:00<00:00, 15216077.29it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "from gen_model_with_sinkhorn import Model\n",
        "\n",
        "import torch\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "\n",
        "#PARAMETERS\n",
        "batch_size = 64\n",
        "epochs = 20\n",
        "generator_dim = [[2,32], [32,128], [128, 784]] #last one should be [_,784]\n",
        "learned_cost_dim = [[784, 128], [128, 128]] #first one should be [784, _]\n",
        "lr = 0.01\n",
        "learnable_cost = False\n",
        "epsilon = 0.1\n",
        "\n",
        "model = Model(generator_dim, learned_cost_dim, batch_size, lr, epsilon, learnable_cost)\n",
        "\n",
        "#to use normalized version of MNIST\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5,), (0.5,))\n",
        "])\n",
        "\n",
        "# Download and load the MNIST dataset\n",
        "train_dataset = datasets.MNIST(root='./data', train=True, transform=transform, download=True)\n",
        "test_dataset = datasets.MNIST(root='./data', train=False, transform=transform, download=True)\n",
        "\n",
        "\n",
        "# Flatten 28x28 image into a vector= of 784 fetures\n",
        "flatten = transforms.Lambda(lambda x: x.view(-1))\n",
        "\n",
        "# Apply the flatten transformation to the dataset\n",
        "train_dataset.transform = transforms.Compose([transform, flatten])\n",
        "test_dataset.transform = transforms.Compose([transform, flatten])\n",
        "\n",
        "# Create dataloaders\n",
        "train_dataloader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
        "test_dataloader = DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c46b4c42",
      "metadata": {
        "id": "c46b4c42",
        "outputId": "44c35aa0-bb77-42ff-e657-7b9cb2a2994c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "End of the epoch due to the end of the for loop on k.\n",
            "epoch1: loss = 3396.7279777526855\n",
            "\n"
          ]
        }
      ],
      "source": [
        "#training\n",
        "for epoch in range(1,epochs+1):\n",
        "    model.train(True)\n",
        "    loss = model.train_1epoch(train_dataloader)\n",
        "    print(f\"epoch{epoch}: loss = {loss}\\n\")\n",
        "\n",
        "torch.save(model, \"basic_model.pt\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import visualization.py"
      ],
      "metadata": {
        "id": "RGS2GjgeMqXO"
      },
      "id": "RGS2GjgeMqXO",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}